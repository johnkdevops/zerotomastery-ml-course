{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637d8f46-4f60-4a18-afed-286f7f3e80cd",
   "metadata": {},
   "source": [
    "## Introduction to Scikit-Learn (sklearn)\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "What we're going to cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de254f6-6a6e-4f67-843a-1f21114fceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listify the contents\n",
    "what_were_covering = [\n",
    "    \"0. An end-to-end Scikit-Learn workflow\",\n",
    "    \"1. Getting the data ready\",\n",
    "    \"2. Choose the right estimator/algorithm for our problems\",\n",
    "    \"3. Fit the model/algorithm and use it to make predictions on our data.\",\n",
    "    \"4. Evaluating a model\",\n",
    "    \"5. Improve a model\",\n",
    "    \"6. Save and load a trained model\",\n",
    "    \"7. Putting it all together!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23efa319-851a-48b6-9bf5-e1e00d8e7af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data.',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f8999-dbe7-4b61-8230-19ea976cddbc",
   "metadata": {},
   "source": [
    "<img src=\"./Images/sklearn-workflow-title.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ea425f-bfd7-471e-af63-4ac799cc02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72aa4e2-d8a8-4e34-a4bc-451b67bb8100",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a27063-7b10-4096-950b-dd1922170d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
       "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
       "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  \n",
       "5   0     1       1  \n",
       "6   0     2       1  \n",
       "7   0     3       1  \n",
       "8   0     3       1  \n",
       "9   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the data ready\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "heart_disease = pd.read_csv(\"./data/heart-disease.csv\")\n",
    "heart_disease.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a36670-1cae-4626-88aa-0365c1bd4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (feature matrix)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ee53de-9c97-41e0-a892-b2ac5854645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8d0f90-2389-4d08-a9b5-94a80c3b9749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c651785a-be63-460d-93c9-43041bafb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2208757a-71db-430e-a925-c7bc34ecb576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "executable: C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\python.exe\n",
      "   machine: Windows-10-10.0.19045-SP0\n",
      "\n",
      "Python dependencies:\n",
      "      sklearn: 1.5.1\n",
      "          pip: 24.2\n",
      "   setuptools: 75.1.0\n",
      "        numpy: 1.26.4\n",
      "        scipy: 1.13.1\n",
      "       Cython: None\n",
      "       pandas: 2.2.2\n",
      "   matplotlib: 3.9.2\n",
      "       joblib: 1.4.2\n",
      "threadpoolctl: 3.5.0\n",
      "\n",
      "Built with OpenMP: True\n",
      "\n",
      "threadpoolctl info:\n",
      "       user_api: blas\n",
      "   internal_api: mkl\n",
      "    num_threads: 4\n",
      "         prefix: mkl_rt\n",
      "       filepath: C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Library\\bin\\mkl_rt.2.dll\n",
      "        version: 2023.1-Product\n",
      "threading_layer: intel\n",
      "\n",
      "       user_api: openmp\n",
      "   internal_api: openmp\n",
      "    num_threads: 8\n",
      "         prefix: vcomp\n",
      "       filepath: C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\vcomp140.dll\n",
      "        version: None\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc32053-c15f-4749-a88b-0c1f457f3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd0f00c-844e-4f47-8df0-9439f5a7c560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "140   51    0   2       120   295    0        0      157      0      0.6   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "288   57    1   0       110   335    0        1      143      1      3.0   \n",
       "45    52    1   1       120   325    0        1      172      0      0.2   \n",
       "32    44    1   1       130   219    0        0      188      0      0.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "265   66    1   0       112   212    0        0      132      1      0.1   \n",
       "116   41    1   2       130   214    0        0      168      0      2.0   \n",
       "210   57    1   2       128   229    0        0      150      0      0.4   \n",
       "62    52    1   3       118   186    0        0      190      0      0.0   \n",
       "282   59    1   2       126   218    1        1      134      0      2.2   \n",
       "\n",
       "     slope  ca  thal  \n",
       "140      2   0     2  \n",
       "16       2   0     2  \n",
       "288      1   1     3  \n",
       "45       2   0     2  \n",
       "32       2   0     2  \n",
       "..     ...  ..   ...  \n",
       "265      2   1     2  \n",
       "116      1   0     2  \n",
       "210      1   1     3  \n",
       "62       1   0     1  \n",
       "282      1   1     1  \n",
       "\n",
       "[242 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b05270-8fef-454b-994e-4f292ca9dece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\executing\\executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make a prediction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_label \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]))\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa505fc8-f2f1-4630-bc13-839b889a1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test);\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fa23b-d9e7-482a-ad0a-f4a289635744",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b324b89-4f19-4af3-9ab0-4bd060b51636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "clf.score(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa258e-be7c-4a9b-90a6-bf93b46b2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8ab2a-e1cf-49de-a64b-41d019629ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0465cdc-eba6-4bf2-9648-9a348171b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cce0f-8e2e-4d6a-a144-843345ceab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d43f5-297b-47dc-b306-152691281975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve a model\n",
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f7f5b-024d-4efd-b597-56b15c8f9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31c5f2-e15b-4bd7-9ff8-c5ef5b7b17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pk1\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8e932-361a-49ca-a7b6-5557e2fc03b3",
   "metadata": {},
   "source": [
    "## 1. Getting our data ready to be used with machine learning\n",
    "\n",
    "Three main things we have to do:\n",
    "\n",
    "    1. Split the data into features and labels (usually `X` & `y`)\n",
    "    2. Filling (also called imputing) or disregarding missing values\n",
    "    3. Converting non-numerical values to numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8103fd-f1b1-41ae-9f0c-361d5927ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e9fe1-6380-4b77-967e-2bee413a1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is feature dataset for ml\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f5103-b93a-4d7b-92c9-2a25a212cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca78ddf-3cac-4125-8c6a-4aa1cd9a1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7016be-5e75-46d5-816c-934f45536845",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035ffd3-553b-49be-87cc-fc34209c17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d0ba7-076c-4f35-a0e4-e39f0861b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "242.4 + 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23a3fe-430d-43da-8a23-459243a2c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bc0db-7aa2-4cbc-9f61-02a5361bc5cf",
   "metadata": {},
   "source": [
    "### 1.1 Make sure it's all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9bf89e-5c00-4e1f-92e9-9807d189801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"./Data/car-sales-extended.csv\")\n",
    "car_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1d2a9-c4c0-45e8-bf8c-09bff693721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63216251-f599-4ce0-abcc-fff713cafd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738de971-747c-4f03-a9e9-cb4c725fa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X/y\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24affff-ac55-4b36-8e52-859c584504ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496080d-ab89-434b-8df1-781c8e85270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb8a7b-ea7c-4934-a7bb-e4c2d6c56b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11085821-f4df-4b7d-b838-ccb04c0eb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288c4f6-5633-42f2-8605-ce6e2ec00d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03277a5-913f-4bbc-ae1e-e5049214cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]]).astype(int)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10291ba-9187-492a-bf5b-7fcfb00e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8ed69-8fed-4bcf-b1d3-5108a8b885f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0181fa-2d72-4bdb-b501-fc65640d9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ab569-4db3-444f-b1b0-8743e146b169",
   "metadata": {},
   "source": [
    "### 1.2 What if there missing values?\n",
    "\n",
    "1. Fill them with some value (also known as imputation).\n",
    "2. Remove the samples with missing data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcf4a0-3375-4dd6-96b0-5731bb840eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd6665-7bca-41cd-9cd8-efa183494e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccaae88-00e9-4a9f-baf1-d54c142e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "X = car_sales_missing.drop([\"Price\"], axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba058cfe-1233-4711-8e46-a73243492421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c1e33-d3a0-4bbd-ab7c-33b2ec85e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d7db3-3001-4fdd-8576-ec97168ddb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748e0ff-2da9-4135-90c8-fc352aa336d9",
   "metadata": {},
   "source": [
    "#### Option 1: Fill missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e1266-15dd-45f7-8269-c2129cfa4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"] = car_sales_missing[\"Make\"].fillna(\"missing\")\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"] = car_sales_missing[\"Colour\"].fillna(\"missing\")\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"] = car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(numeric_only=True))\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"] = car_sales_missing[\"Doors\"].fillna(4)\n",
    "\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348962a-2b80-4d2a-b0f1-8209541df21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693485a1-5315-42b4-b1d9-cb8f16aa46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price values\n",
    "car_sales_missing = car_sales_missing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89f16b-158b-4c70-89d8-f52e86f96650",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d045b20-b997-42cf-b51d-81f8b8070d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d797a03-be5a-49ad-9af2-2ce236460f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "X = car_sales_missing.drop([\"Price\"], axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37737f35-3e35-4997-a526-721487bda4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed112e6-bac6-4112-92da-755400043033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397409c7-f9db-4fcf-834b-35aec1f62b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8635e-1120-4948-8f20-c870e936960e",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d6a80-a2d1-46da-96f4-316139193943",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cfa09-aa7a-41a4-9563-39e466d6ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dab5c-c7bb-40e3-9a48-4cf7bb7212ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with no labels in \"Price\" column\n",
    "car_sales_missing = car_sales_missing.dropna(subset=[\"Price\"])\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18408507-5f38-44df-9eff-5562a1c7c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y\n",
    "X = car_sales_missing.drop([\"Price\"], axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1aad2-fe5c-44e0-b15a-2ba00acea1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with Scikit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill catergorical values with 'missing' & numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d53221-3651-4a23-a4db-a9898878b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X,\n",
    "                               columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d2a54-a4ea-4a58-9ee2-29e73ab9088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ca226-bf74-41b8-a686-0f53b3549a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c0b09-9bf6-425d-a94d-c35d86eb99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca434aa9-0f34-4f7d-812e-e1c71a0555cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2866c-4bce-43b3-a196-9c58d3e29188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c56fe-877b-441b-9d03-c9b6b8673823",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_filled), len(car_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9925f-343c-4b31-8795-f886963c66ac",
   "metadata": {},
   "source": [
    "Note: The 50 less values in the transformed data is because we dropped the rows (50 total) with missing values in the Price column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87deb563-b3e1-4480-9e36-10b5eb4ba885",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "* Sklearn refer to machine learning models, algorithms as estimators.\n",
    "* Classification problem - predicting a category (heart disease or not)\n",
    "    * Sometimes you'll see `clf` (short for classifier) used as a classification estimator\n",
    "* Regression problem - predicting a number (selling price of a car)\n",
    "\n",
    "if you're working on a machine learning problem and looking to use Sklearn and not sure what model you should use, refer to the sklearn machine learning map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68610564-88ea-4e89-96d5-41c15b2d9e11",
   "metadata": {},
   "source": [
    "### 2.1 Picking a machine learning model for a regression problem\n",
    "\n",
    "Let's use California Housing dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d4e5ccf-7eb4-40e4-ad89-adf0fe57c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get California Housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff1714d-e7fc-4b03-9c28-4b8730797339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3ffd60-d3db-41e2-a3c5-ce17c60a0254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d6cb375-8f45-4c48-a506-27e1a54df061",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['MedHouseVal'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m housing_df \u001b[38;5;241m=\u001b[39m housing_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedHouseVal\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['MedHouseVal'] not found in axis\""
     ]
    }
   ],
   "source": [
    "housing_df = housing_df.drop(\"MedHouseVal\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57af6adb-7915-40b1-8d78-7f5ea261e998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62bf75b4-350e-4049-8274-0b2de251f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440126"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using the RidgeRegressor model\n",
    "# Import algorithm/estimator\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f39c8-64b9-42b9-9f44-dc6759b99f43",
   "metadata": {},
   "source": [
    "What if `Ridge` didn't work or score didn't fit our needs?\n",
    "\n",
    "Well, we could always try a different model...\n",
    "\n",
    "How about we try an ensemble model ( an ensemble is combination of smaller models than just a single model)?\n",
    "\n",
    "Sklearn's ensemble models can be found here: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e800111-0d62-4c0e-a5ba-030c694d6b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2841671821008396"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using the Lasso model\n",
    "# Import algorithm/estimator\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29277022-919a-43bc-b921-6b5fd60dbba0",
   "metadata": {},
   "source": [
    "Note: Lasso model not really good at predicting the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ffda69-1822-4db0-ad26-3001b28eae53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using the Ensemble RandomForest Regressor model using (Decision Trees)\n",
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594196d4-ddd5-4a24-a754-251e2f5e3c66",
   "metadata": {},
   "source": [
    "Note: Ensemble RandomForestRegressor Model wins!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d1d652-5bf1-418b-8a74-5f76580aaa6f",
   "metadata": {},
   "source": [
    "## 2.2 Choosing an estimator for a classification problem\n",
    "\n",
    "Let's go to the map.. https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b67b473-3ca0-4591-93c1-629869c1824f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"./data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b925da54-83a7-47e7-981c-b8f30d60ce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365d08b-882b-41bd-a1dd-6ec6d3e4f704",
   "metadata": {},
   "source": [
    "Consulting the map and it says to try LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24cfbcc1-6151-4a44-9895-aa78446a2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688524590163934"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LinearSVC estimate class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"] # heart disease yes/no?\n",
    "\n",
    "# Split the data into train and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "811309e4-0abc-4100-a549-34d092b936dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    165\n",
       "0    138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ef25b07-7cfb-434e-aa87-594bc9d53102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"] # heart disease yes/no?\n",
    "\n",
    "# Split the data into train and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30b640-83be-44f8-8bee-2f2ba812012f",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "    1. If you have structured data, use ensemble methods\n",
    "    2. If you have unstructured data, use deep learning or transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83167941-043f-41f2-a0ee-1680e12ec0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8541f2d-8274-48da-987d-c066aeb76b9f",
   "metadata": {},
   "source": [
    "## 3. Fit the model/algorithm our data and use it to make predictions\n",
    "\n",
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different name for:\n",
    "\n",
    "* X = features, variables, data\n",
    "* y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44523c1f-b41b-4c9f-8a62-bd7510c9cb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"] # heart disease yes/no?\n",
    "\n",
    "# Split the data into train and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the RandomForestClassifier (use the patterns that model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2f336b7-772b-4d86-8ae3-2e2088ff4645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daf6bf9e-ed79-4796-8ce3-4cbaa389d162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27121f8-7049-4c2b-af86-0dca4fa7b988",
   "metadata": {},
   "source": [
    "### 3.2 Make predictions using a machine learning model.\n",
    "\n",
    "2 ways to make predictions:\n",
    "\n",
    "  1. predict()\n",
    "  2. predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bc105-be87-47a0-84f4-a5d97cc7f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used a trained model to make predictions\n",
    "clf.predict(np.array([1, 7, 8, 3, 4])) # this doesn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8faf5d9-e021-4cb3-8aea-90733386f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bf129-7c75-4936-9934-9a4208e9ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test) # This is like the machine learning model taking the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72b47d-3093-41e7-a178-0970878e8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([y_test]) # This is exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8551ba-c9a2-4199-80d4-b60b2945287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2adccf-a0f9-49d7-af8c-d4d25417e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187dad9-e70d-4c59-b9a8-b76b65d90155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bca815-730f-4db9-bc90-5ff1ad090da0",
   "metadata": {},
   "source": [
    "Make predictions with `predict_proba()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc4c67-e143-4911-99b1-8cbcb72a83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_prob() returns probabilities of a classification label\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ec8e8-a6a1-4206-8ed8-3a9211bc3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's predict() on the same data..\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6e2cc-f286-46cb-a85f-bffa428c96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7e3e2-92ef-42c2-b521-16a8dbec391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe0263-beb1-4d1f-9bca-770abd3fee96",
   "metadata": {},
   "source": [
    "`predict()` can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a1f1b-3594-41f6-b89b-66d4cbfb5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05a59c-0a4c-4213-8e92-d54dc09a16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca107d7-8916-41ce-86f6-f57f81740d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edbc84-9d48-4a1f-8755-cb937aa12605",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece7af7-b02b-47ed-bdd1-66671d08894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e8460-8229-40cf-b50c-883aa859947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78410533-f630-47df-a2e1-965b52ed3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d91d8-93a7-46a2-92a7-968915ff57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a63024-8733-4bbd-ade4-bda66bde4d85",
   "metadata": {},
   "source": [
    "## 4. Evaluating a machine learning  model\n",
    "\n",
    "Three ways to evaluate Scikit-Learn models/estimators\n",
    "\n",
    "    1. Estimator's built-in `score()` method\n",
    "    2. The `scoring` parameter\n",
    "    3. Problem-specific metric functions\n",
    "\n",
    "You can read more about these here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfa8be-28c4-43ad-afa0-8a4160e9b405",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model with score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1855e-0b57-4ebe-81fc-69cef6f36295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"] # heart disease yes/no?\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb611d-f64a-46a7-b1ad-995d8cd54bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest value for the .score() method is 1.0, the lowest is 0.0\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4db5d8-6203-4437-9c8a-0472b4b832bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f406c-c4fd-4eb9-a0d6-5d537990e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b5c86-a32b-4e1a-87b5-eb62d25501a2",
   "metadata": {},
   "source": [
    "Let's use the `score()` on our regression problem... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439791c-a14a-48ff-a991-92fdbc814709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create model instance\n",
    "model = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9842e-0606-4128-9072-515f3915c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default score() evaluation is r_squared for regression algorithms\n",
    "# Highest = 1.0, lowest = 0.0\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a82193-0974-4e6a-8878-045970f2f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2f657-167b-464e-860d-326afe35dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e570f5-2f4e-4fa8-bad3-1ca220ace6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f21165-90fb-4b60-b9fb-f4fd2d2ac220",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating a model using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34669a5-6c64-45ca-9d3f-c466546a0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"] # heart disease yes/no?\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58493062-41c9-4c31-82a8-a1f5487ed20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d1915-34c0-49d1-ab00-164a93c078bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40e5ad-b913-4692-b5fe-782269364b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e59a6-09a2-434a-80a7-aefc7b869fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "# Compare the two\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc655c-3ecd-4516-bcbc-8619ce978823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scoring parameter of classifier = mean accuracy\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d655809-3bd6-45c3-ba4f-b6dfb73bdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf, X, y, cv=5, scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f40cad-39fa-43b6-a651-46031ccf0b41",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426b85c-d4d2-4497-abd2-808e2f879ac4",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492a312-0478-4273-8e53-aa73f4f9a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfd921-5ee2-493c-b06a-a736b5dc82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5658592-2de6-401f-a289-20c33614c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26aa17-d900-4d44-abbe-8bf7e77e26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadaca33-9dc9-41d1-ab65-7b71ff265021",
   "metadata": {},
   "source": [
    "**Area under receiver operating characteristic curve (AUC/ROC)**\n",
    "\n",
    "* Area under curve (AUC)\n",
    "* ROC curve\n",
    "\n",
    "ROC curves are a comparison of a model's true positive rate (tpr) versus a models false positive rate (fpr).\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when the truth is 0\n",
    "* True negative = model predicts 0 when the truth is 0\n",
    "* False negative = model predicts 0 when truth is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50f144-d2bf-45f5-8c32-44f41d1db78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_test... etc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e5e13-ce5c-4eb9-a058-124bf9871bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56900d-0fd6-430a-aec5-8dff12c56965",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_positive = y_probs[:, 1]\n",
    "y_prob_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5decab52-01e5-4ae4-843c-aeb201f07650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_positive)\n",
    "\n",
    "# Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7720c-12bf-4786-9922-8b7e0c6724cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr)\n",
    "    and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # Plot roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aab36e-67f3-441c-b79e-dcf9c2a9528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03e88e-bdc6-4e8b-bb2b-d355b9a036ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6847896-ebd8-48da-a29b-e554fee1cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e9436-bc8b-4917-991c-8623e0d79044",
   "metadata": {},
   "source": [
    "**Confusion matrix**\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actula labels it was supposed to predict.\n",
    "In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f2283deb-c059-4269-bbed-826845700db1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 3\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m confusion_matrix(y_test, y_preds)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:944\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    923\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 944\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m    946\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0734dfa-fe8c-4c35-a926-62d4231b568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "            rownames=[\"Actual Labels\"],\n",
    "            colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edd104-ccea-4e03-8854-2a2560f316e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "22 + 7 + 8 + 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75307f5e-2b87-417a-a20d-edfe9435b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e0978-e015-4a44-bcc7-e678688082d6",
   "metadata": {},
   "source": [
    "**Creating a confusion matrix using Scikit-Learn**\n",
    "\n",
    "To use the new methods of creating a confusion matrix with Scikit-Learn you will need sklearn version 1.0+- https://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ed7fb-919e-434f-a859-4d17b576af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4f7cbd54-d1f0-4656-aa13-3babe04db4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\executing\\executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a confusion matrix\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m conf_mat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_preds)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot it using Seaborn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(conf_mat);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# Plot it using Seaborn\n",
    "sns.heatmap(conf_mat);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd222fa-525c-45cd-aafd-11f8d3bab7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928bc73-d110-482c-98b7-22271021385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d249a0-adc5-42f8-a2f2-9540b0e8b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test,\n",
    "                                        y_pred=y_preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d277c33-1286-441b-8214-ba100093fb60",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6ea4c0b2-9514-4f11-a93b-8c29b720a5dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [190, 45]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_preds))\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2626\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2491\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2492\u001b[0m     {\n\u001b[0;32m   2493\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2517\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2518\u001b[0m ):\n\u001b[0;32m   2519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2520\u001b[0m \n\u001b[0;32m   2521\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2626\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2629\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [190, 45]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00e51f-3b92-4516-9021-f05659ab188a",
   "metadata": {},
   "source": [
    "**Classification Report Anatomy**\n",
    "\n",
    "* **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "* **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "* **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "* **Support** - The number of samples each metric was calculated on.\n",
    "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "* **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "* **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885df92-6541-4b0b-ad70-e2433a5598e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f3c0b-a0da-4526-ad2f-1a14d3f1be05",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "Model evaluation metrics documentation - https://scikit-learn.org/stable/modules/module_evaluations#html\n",
    "\n",
    "The ones we're going to cover are:\n",
    "1. R^2 (pronounced r-squared) or coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3ac85-ee35-4a6b-9fa9-2bbc51da3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6e20a-02d0-4dad-b095-3f8b66c70e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799f325-8fb9-4363-9030-349f20e251bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1f3bf-fcaa-4b31-b9f3-727dcbf1b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056bd02-58b8-41f8-a5b7-3d3ff015fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b32e6-5ea3-48b7-935b-16f776e356f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918efbc0-5d01-47f9-bdcd-8b10eac11179",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b89983-cebe-482b-88da-4dd492480ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test, \n",
    "         y_pred=y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e937d34-3bc7-4a0b-b710-33b13f533ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test,\n",
    "         y_pred=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34abbb-f2fa-4bfd-8abe-812696336119",
   "metadata": {},
   "source": [
    "**Mean absolute error (MAE)**\n",
    "\n",
    "MAE is the average of the absolute differences between predictions and actual values.\n",
    "\n",
    "It gives you an idea of how wrong your predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fddfb8-da91-40bd-adee-90fdd76f2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598d3f2-b7ef-4c59-ba17-5460100c4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013960d3-9831-4f3b-b4f9-a342fe28c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571bea4d-caf7-4f7c-ad5c-0006aedafe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test,\n",
    "                        \"predicted values\": y_preds})\n",
    "df[\"differences\"] = df[\"predicted values\"] - df[\"actual values\"]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30c0d8-156a-477b-a383-56985bcad8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163610c-6852-4bfa-b3e6-2b5183f70a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE using formulas and differences\n",
    "np.abs(df[\"differences\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fa9be-dbbd-4095-b6d8-3cfe62cf6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Mean squared error (MSE)**\n",
    "\n",
    "MSE is the mean of the square of the errors between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03e43e-c309-4701-83bf-2ace9657f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61918a7d-d352-460a-83da-7a1087809094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"squared_differences\"] = np.square(df[\"differences\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc4453-544d-4a4a-b262-6f1e963b0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE by hand\n",
    "squared = np.square(df[\"differences\"])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70401236-714a-41b7-b024-55cdd64ec386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error = df.copy()\n",
    "df_large_error.iloc[0][\"squared_differences\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de2944-9d38-4f11-8a4e-8b6e799025f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19397528-5834-4b27-8ee6-20071afb6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE with large error\n",
    "df_large_error[\"squared_differences\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d826d1-9819-4e8a-8562-89c257be4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_error.iloc[1:100] = 20\n",
    "df_large_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a566138-64a5-4c11-8a10-0c87c67291e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE with large error\n",
    "df_large_error[\"squared_differences\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463abec-7c6a-4bdf-b11a-11945ce0a8ff",
   "metadata": {},
   "source": [
    "Now you might be thinking, which regression evaluation metric should you use?\n",
    "\n",
    "* **R^2** is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your **R^2** value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "* **MAE** gives a better indication of how far off each of your model's predictions are on average.\n",
    "* As for **MAE** or **MSE**, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
    "  \n",
    "* Pay more attention to MAE: When being \\$10,000 off is **twice** as bad as being \\$5,000 off.\n",
    "* Pay more attention to MSE: When being \\$10,000 off is **more than twice** as bad as being \\$5,000 off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0986f-90d1-4500-afde-9745839c5166",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504cb1a5-2eaa-4cad-b3ce-29991b7021de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef86e72-74e8-4d41-b1ce-f60e0aada5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None) # if scoring=None, estimator's default scoring evaluation metric is used (accuracy for classification models)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf92e8a8-4318-4f4b-b4cc-c36ef77735f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is 82.48%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90ffba0-d5a6-4cc7-9ae3-41bac716a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf41a407-dafb-495e-82fc-75b39b5ae188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is 82.48%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8253070e-3502-4138-8861-a8d014500927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82352941, 0.93548387, 0.84848485, 0.79411765, 0.76315789])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation precision\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d257cd39-2a95-43ab-b041-6e9f5fb03579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated precision is 0.8330\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated precision\n",
    "print(f\"The cross-validated precision is {np.mean(cv_precision):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "733f8a54-a3c4-4aef-ab17-c634a977f686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84848485, 0.87878788, 0.84848485, 0.81818182, 0.87878788])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation recall\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b51c89d7-a2f3-45b1-941d-01cddbda4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated recall is 0.8545\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated recall\n",
    "print(f\"The cross-validated recall is {np.mean(cv_recall):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c6de880-d12f-4e68-ae91-096f743231d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\site-packages\\executing\\executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "C:\\KodeKloud_Pro\\Google Cloud\\Google Cloud Platform Engineer\\zerotomastery\\AI ML Engineer\\DataScienceAndMLBootcamp\\sample_project\\env\\Lib\\ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'housing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m housing_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m housing_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# median house price in $100,000s \u001b[39;00m\n\u001b[0;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'housing_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5bf21-1116-4da6-80c5-1a3b98740082",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bdd81-689b-4859-9cb0-082f3c2c186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e168-7439-4907-a4ce-d371602b112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "cv_mae = cross_val_score(model, X, y, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1404970-af80-427a-99cc-94fd1664820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f2869-d8ee-4f09-9fda-d65568cea54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cv_mse = cross_val_score(model, X, y, cv=3, scoring=\"neg_mean_squared_error\")\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae7c4c-dfa7-479b-8f5f-b84e9a1318f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6235c58-291b-4ce7-8e8e-23e25b77be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression model metrics on the test set:\")\n",
    "print(f\"R^2: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44879bd-f587-469f-a6d7-88279d2ca492",
   "metadata": {},
   "source": [
    "## 4.3 Using different evaluation metrics as Scikit-Learn functions\n",
    "\n",
    "The 3rd way to evaluate sckikit-learn machine learning models/estimators is using the sklearn.metrics module - https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33f2e040-10a6-4bbd-bcd9-8e4bf9070f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics on the test set:\n",
      "Accuracy: 85.25%\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(\"Classifier metrics on the test set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds):.2f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f072006e-bfe7-429d-ab11-4e72601d9507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression metrics on the test set:\n",
      "R2 score: 0.81\n",
      "MAE:      0.33\n",
      "MSE:      0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"] # median house price in $100,000s \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Regression metrics on the test set:\")\n",
    "print(f\"R2 score: {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"MAE:      {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"MSE:      {mean_squared_error(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740d698-57df-4669-87e3-045288845fde",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "First predictions = baseline predictions.\n",
    "First model = baseline model.\n",
    "\n",
    "From a data perspective:\n",
    "* Could we we collect more data (generally, the more data, the better)\n",
    "* Could we improve our data?\n",
    "\n",
    "From a model perspective:\n",
    "* Is there a better model we can use?\n",
    "* Could we improve the current model?\n",
    "\n",
    "Hyperparameters vs. Parameters\n",
    "Parameters = model find these patterns in data\n",
    "Hyperparameters = setting on a model you can adjust to (potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37ffea9b-4c2c-4574-9211-335d55cb6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db326fe-9ea6-460e-af4e-68e2817468e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097a200-640d-49b9-8a92-51be84c523ac",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets: training, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d29bd2-bd51-4434-8677-d1027119389c",
   "metadata": {},
   "source": [
    "We're going to try and adjust:\n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58ab8a1e-fa42-4fe0-bc6e-a503b3317cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true: np.array, \n",
    "                   y_preds: np.array) -> dict:\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "\n",
    "    Returns several metrics in the form of a dictionary.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2), \n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee551f43-ad12-406b-b937-c5f1396c61f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e301c49f-8db9-4f5b-9949-cd6dc2e011b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 45, 46)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15 % of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45aa64c8-6155-4d4e-ba03-4035b1916872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 80.00%\n",
      "Precision: 0.77\n",
      "Recall: 0.92\n",
      "F1 score: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.77, 'recall': 0.92, 'f1': 0.84}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline prediction which must be on the validation set\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b5f37d0-5690-4160-8083-0d6e9b58eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.84, 'recall': 0.84, 'f1': 0.84}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)\n",
    "clf_2_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2c3f130c-692c-47bd-a0b6-10e15c456dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.84, 'recall': 0.84, 'f1': 0.84}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a third classifier with different hyperparameters\n",
    "clf_3 = RandomForestClassifier(n_estimators=100, \n",
    "                               max_depth=10)\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_3 = clf_3.predict(X_valid)\n",
    "\n",
    "# Evaluate the 3rd classifier\n",
    "clf_3_metrics = evaluate_preds(y_valid, y_preds_2)\n",
    "clf_3_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b924d56-b379-40a4-981c-9d3588e92d39",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameters tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc606440-905f-4d4b-8668-5055672d435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1440 potential combinations of hyperparameters to test.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "                       \"max_depth\": [None, 5, 10, 20, 30],\n",
    "                       \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                       \"min_samples_split\": [2, 4, 6, 8],\n",
    "                       \"min_samples_leaf\": [1, 2, 4, 8]}\n",
    "\n",
    "# Count the total number of hyperparameter combinations to test\n",
    "total_randomized_hyperparameter_combintions_to_test = np.prod([len(value) for value in param_distributions.values()])\n",
    "print(f\"There are {total_randomized_hyperparameter_combintions_to_test} potential combinations of hyperparameters to test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26fc4988-2fad-4ece-b70b-24297a867083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   1.8s\n",
      "[INFO] Total time taken for 10 random combinations of hyperparameters: 56.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Set n_jobs to -1 to use all available cores on your machine (if this causes errors, try n_jobs=1)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Setup RandomizedSearchCV \n",
    "n_iter = 10 # try 30 models total\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=param_distributions,\n",
    "                            n_iter=n_iter, \n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf (does cross-validation for us, so no need to use a validation set)\n",
    "rs_clf.fit(X_train, y_train);\n",
    "\n",
    "# Finish the timer\n",
    "end_time = time.time()\n",
    "print(f\"[INFO] Total time taken for {n_iter} random combinations of hyperparameters: {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df5fafbc-8647-44f9-a5aa-ed3f32a3c94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "42d7d25d-620c-4d0e-a5b4-0dd29998a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 80.33%\n",
      "Precision: 0.75\n",
      "Recall: 0.86\n",
      "F1 score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e9537-855e-42bc-98a2-3a0c772d3dab",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55602be6-8dfb-4dc0-affc-f02e831142f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['sqrt', 'log2', None],\n",
       " 'min_samples_split': [2, 4, 6, 8],\n",
       " 'min_samples_leaf': [1, 2, 4, 8]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6461404-80c9-4cd4-bdee-15166c4dfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "          'max_depth': [20],\n",
    "          'max_features': ['sqrt', 'log2'],\n",
    "          'min_samples_split': [6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44da0527-b120-4fe5-af01-7205a4cd3b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*1*2*1*2*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ccbaae1-294e-42ce-816d-959d4dfd3904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.7s\n",
      "[INFO] Total time taken for 10 random combinations of hyperparameters: 124.73 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Set n_jobs to -1 to use all available cores on your machine (if this causes errors, try n_jobs=1)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "n_iter = 10 # try 30 models total\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                            param_grid=grid_2,\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf (does cross-validation for us, so no need to use a validation set)\n",
    "gs_clf.fit(X_train, y_train);\n",
    "\n",
    "# Finish the timer\n",
    "end_time = time.time()\n",
    "print(f\"[INFO] Total time taken for {n_iter} random combinations of hyperparameters: {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c4f6e14-9920-416a-aeab-2fd0ca66e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fdc35f8-6f0b-46c0-9b42-b101625b1c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 score: 0.78\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00784a2-e3ab-4cd8-ad8a-8b32d7a75a2a",
   "metadata": {},
   "source": [
    "Let's compare our different models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc51d635-cb59-4661-844b-4b83699ad1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metric,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "compare_metrics.plot.bar(figsize=(10, 8));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1640225-169f-4985-837d-7741fb262632",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained machine learning models\n",
    "\n",
    "Two ways to save and load machine learning models.\n",
    "\n",
    "    1. With Python's `pickle` module\n",
    "    2. With the `joblib' module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a68c9dd6-7727-4617-9b4d-81dea2d10327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "best_model_file_name_pickle = \"gs_random_random_forest_model_1.pkl\" # .pkl extension stands for \"pickle\"\n",
    "\n",
    "# Using 'with' ensures the file is closed properly\n",
    "with open(best_model_file_name_pickle, \"wb\") as file:\n",
    "    pickle.dump(gs_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7eb5a6f1-4a74-4160-b8ac-21d3a5888ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1),\n",
      "             param_grid={'max_depth': [20], 'max_features': ['sqrt', 'log2'],\n",
      "                         'min_samples_leaf': [1, 2], 'min_samples_split': [6],\n",
      "                         'n_estimators': [100, 200, 500]},\n",
      "             verbose=2)\n"
     ]
    }
   ],
   "source": [
    "# Load a saved model\n",
    "with open(best_model_file_name_pickle, \"rb\") as file:\n",
    "    loaded_pickle_model = pickle.load(file)\n",
    "\n",
    "# Now you can use the 'loaded_model' as needed\n",
    "print(loaded_pickle_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ee42ae2-a8af-4d7a-bec4-4370effeaa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79, 'precision': 0.74, 'recall': 0.82, 'f1': 0.78}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5633ab-6d78-44a8-b179-992990fe5f25",
   "metadata": {},
   "source": [
    "**Joblib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "327cd9fb-b467-4758-bca3-fe63e1c86347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to file\n",
    "dump(gs_clf, filename=\"./models/c_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d2f40ec-e922-4b63-b4b4-1cb40833c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"./models/gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e0b189c9-8a9a-4079-9153-c4a664c83bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79, 'precision': 0.74, 'recall': 0.82, 'f1': 0.78}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and evaluate joblib predictions\n",
    "joblib_y_preds = loaded_job_model.predict(X_test)\n",
    "evaluate_preds(y_test, job_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ee293-ea71-4e2b-abe6-6b8a328edbfd",
   "metadata": {},
   "source": [
    "# 7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1aa46732-2a70-4960-a58c-94f97e508f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "75a41994-2651-4766-9dba-ccc2884003b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "591eb68c-d452-43f9-b599-f6f3568ce1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ec154-5ec1-4b8f-a694-7eddbc872b4f",
   "metadata": {},
   "source": [
    "Steps we want to do (all in one cell):\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6e731e2d-fa2a-4f11-b309-ad5c893a8655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "data = data.dropna(subset=[\"Price\"])\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "categorial_features = [\"Make\", \"Colour\"]\n",
    "categorial_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_features = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers\n",
    "preprocessor = ColumnTransformer(\n",
    "                        transformers=[\n",
    "                            (\"cat\", categorial_transformer, categorial_features),\n",
    "                            (\"door\", door_transformer, door_features),\n",
    "                            (\"num\", numeric_transformer, numeric_features)\n",
    "                        ])\n",
    "\n",
    "# Create a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data \n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b636d-5b23-4a2f-b70f-e947f637e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.9s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.5s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.5s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.5s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.5s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.0s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.3s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.4s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.2s\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Use GridSearchCV with our regression Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"sqrt\"],\n",
    "    \"model__min_samples_split\": [2, 4],\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)\n",
    "\n",
    "# Finish the timer\n",
    "end_time = time.time()\n",
    "print(f\"[INFO] Total time taken for grid search: {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a8c3d551-3a92-4750-9e7b-cac22ab6fbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2970584538514702"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d71c0c-1ce6-4a56-8321-3bb82d2b9326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
